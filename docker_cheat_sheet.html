<!DOCTYPE html>
<html lang="en">
    <head>
        <link rel="stylesheet" href="./style.css">
        <title>Durham's Hub</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Caveat:wght@400..700&family=Jersey+25+Charted&family=Josefin+Sans:ital,wght@0,100..700;1,100..700&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Oswald:wght@200..700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
    </head>

    <body>
        <div id="right-panel">
                <div id="changeColorText">Day/Night mode</div>
        </div>

        <div id="main-panel">

            <div id="title-section">
                <h1 id="title">Durham's Hub</h1>
            </div>

            <hr/>
            <div id="navigation-bar">
                <a href="./index.html"><div id="home-button" class="button"><b>home</b></div></a>
                <a href="./posts.html"><div id="posts-button" class="button"><b>posts</b></div></a>
                <a href="./projects.html"><div id="posts-button" class="button"><b>projects</b></div></a>
                <a href="./tutorials.html"><div id="posts-button" class="button"><b>tutorials</b></div></a>
                <a href="./cheat_sheets.html"><div id="posts-button" class="button"><b>cheat sheets</b></div></a>
                <a href="./about_me.html"><div id="about-me-button" class="button"><b>about me</b></div></a>
                <a href="./contacts.html"><div id="contacts-button" class="button"><b>contacts</b></b></div></a>
            </div>
            <hr/>

            <div class="page_body">
                <h1>Docker Cheat Sheet</h1>
                <h2>Introduction</h2>
                <p>
                    This page is a summary of all the useful docker commands I know. I might use it to create a 
                    Docker tutorial one day but, for now, it will simply consist of a list of commands.
                </p>
            
                <h2>Docker Commands</h2>

                <h3>Pull an image from Docker Hub</h3>
                <pre><code>    docker pull &ltimage_name&gt</pre></code>
                <u>note:</u> this command allows us to dowload the image without running it immeditaly


                <h3>Run a container</h3>
                For all of the commands listed here, if the image is not yet on the host, it is pulled from docker hub automatically.
                <ul>
                    <li>
                        <pre><code>docker run &ltimage_name&gt</pre></code>
                        <u>note:</u> this is equivalent to running <code>docker run &ltimage_name&gt:latest</code> - i.e. docker defaults to the <em>latest</em> tag.
                    </li>
                    <li>
                        <pre><code>docker run -d &ltimage_name&gt</pre></code>
                        <u>note:</u> this allows us to run the container in <em>detached</em> mode, i.e. in the background.
                    </li>
                    <li>
                        <pre><code>docker run --name &ltcontainer_name&gt &ltimage_name&gt</pre></code>
                        <u>note:</u> this allows us to choose the name of the container.
                    </li>
                    <li>
                        <pre><code>docker run &ltimage_name&gt:&lttag&gt</pre></code>
                        <u>note:</u> this allows us to specify a tag. See registry website to know the available tags for an imagespecify a tag. See registry website to know the available tags for an image.
                    </li>
                    <li>
                        <pre><code>docker run -it &ltimage_name&gt</pre></code>
                        <u>note:</u> <code>i</code> attaches our stdin to the container (interactive mode - we can give it input) and <code>t</code> attaches to the 
                        container’s terminal (makes the container able to output on our terminal)
                    </li>
                    <li>
                        <pre><code>docker run &ltimage_name&gt &ltcommand&gt</pre></code>
                        <u>note:</u> this allows us to run a shell command on the image <code>&ltimage_name&gt</code> output the result on our terminal, e.g. 
                        <code>docker run python:3.6 cat /etc/*release*</code> to know which OS is used by the <code>python:3.6</code> image.
                    </li>
                    <li>
                        <pre><code>docker run -e &ltenv_var&gt=&ltvalue&gt &ltimage_name&gt </pre></code>
                        <u>note:</u> this allows us to set a particular environment variable to a specific value in the docker container.
                    </li>
                    <li>
                        <pre><code>docker run --entrypoint &ltcommand&gt &ltimage_name&gt </pre></code>
                        <u>note:</u> this allows us to overwrite the command specified in the <code>ENTRYPOINT</code> of the Dockerfile with <code>&ltcommand&gt</code>. See the entry on <code>ENTRYPOINT</code> for more details.
                    </li>
                    <li>
                        <pre><code>docker run --restart=&ltrestart_policy&gt &ltimage_name&gt </pre></code>
                        <u>note:</u> this allows us to set a restart policy for this container. When not specified, it defaults to <code>no</code>. <code>&ltrestart_policy&gt</code> can take values in 
                        the set <code>{no, on-failure, unless-stopped, always}</code>.
                    </li>
                </ul>
                
                <h3>Reattach to a container running in the background</h3>
                <ul>
                    <li><pre><code>    docker attach &ltcontainer_name&gt</code></pre></li>
                    <li><pre><code>    docker attach &ltcontainer_id&gt</code></pre></li>
                </ul>
                <u>note:</u> the two commands are equivalent <br/>
                <u>note:</u> this is useful to re-attach to a container that was started with <code>docker run
                -d &ltimage_name&gt</code>

                <h3>Stop a running container</h3>
                <pre><code>    docker stop &ltcontainer_name&gt</code></pre>

                <h3>List all currently running containers</h3>
                <pre><code>    docker ps</code></pre>

                <h3>List all containers (including stopped ones!)</h3>
                <pre><code>    docker ps -a</code></pre>

                <h3>List all locally downloaded images</h3>
                <pre><code>    docker images</code></pre>

                <h3>Deleting an already stopped container</h3>
                <pre><code>    docker rm &ltcontainer_name&gt</code></pre>
                <u>note:</u> the container must be stoped before deleting it with this command!

                <h3>Deleting an image</h3>
                <pre><code>    docker rmi &ltimage_name&gt</code></pre>
                <u>note:</u> the image must not be used by any container - running or stopped - for us
                to be able to delete it!

                <h3>Port mapping</h3>
                <p>
                    The docker host (the computer the image is running on) has an IP address and
                    each docker container running on it has an internal IP address and an internal
                    port. This means that we can access the docker container at this IP address
                    and port, <b>but only from the host</b>! Anyone not on the host can not access
                    the container this way! To allow external users (users not on the host) to access
                    this docker container, we need to map the internal port of the container to
                    some external port of the host.
                </p>
                <p>
                    E.g. assume the host has IP address <em>192.168.1.5</em> has a docker container
                    running with internal IP address <em>172.17.02</em> and port <em>5000</em>. <b>On the host</b> (and
                    only there!), the docker container can be accessed at <em>http://172.17.02:5000</em>. For
                    external users to be able to access this docker container, we must choose
                    some (arbitrary) port of our host and map port <em>5000</em> of our docker container to
                    this port of our host. We can choose to map it to port <em>80</em> of our host, for
                    example. If we do that, the docker container will be accessible to exetrnal users
                    at IP address <em>192.168.1.5</em> port 80 which corresponds to url <em>http://192.168.1.5:80</em>. To map port <em>5000</em> of the container to port <em>80</em> of our host, we
                    run the command: <code>docker run -p 80:5000 &ltimage_name&gt</code>. In general the
                    command for port mapping is:
                </p>
                <pre><code>    docker run -p &lthost_port&gt:&ltcontainer_port&gt &ltimage_name&gt</code></pre>
                <h3>Volume mapping</h3>
                Each docker container has its own file system. If we delete the container, the
                data stored on it is deleted as well. In case we want this data to be able to
                persists even if the docker container is deleted, we can map a directory inside
                the container to a directory on the host’s file system. This way the container will
                “mount” the external directory inside its directory and all the data will be stored
                on the host - and thus persists in case of a deletion.
                <pre><code>    docker run -v &lthost_dir&gt:&ltcontainer_dir&gt &ltimage_name&gt</code></pre>
                <u>note:</u> <b>the <code>-v</code> syntax is the old way</b>, now we should use <code>--mount</code> instead of -v.<br>
                <u>note:</u> see the <em>docker storage</em> section of this cheat sheet for more
                complete information!

                <h3>Inspect a container</h3>
                (This command returns a lot of data about the container.)
                <ul>
                    <li><pre><code>    docker inspect &ltcontainer_name&gt</code></pre></li>
                    <li><pre><code>    docker inspect &ltcontainer_id&gt</code></pre></li>
                </ul>
                <u>note:</u> the two commands are equivalent<br>
                <u>note:</u> the interal IP and port of the container can be found using this command<br>
                <u>note:</u> the list of all environment variables set on this container can be found using this command

                <h3>See the logs of a detached container that is running in the background</h3>
                <ul>
                    <li><pre><code>    docker log &ltcontainer_name&gt</code></pre></li>
                    <li><pre><code>    docker log &ltcontainer_id&gt</code></pre></li>
                </ul>
                <u>note:</u> the two commands are equivalent

                <h3>Build a docker image from a dockerfile</h3>
                <pre><code>    docker build -t &ltimage_name&gt &ltdir_path&gt</code></pre>
                <u>note:</u> here <code>&ltdir_path&gt</code> is the path of the directory containing the <em>Dockerfile</em> we want to use for our build.<br>
                <u>note:</u> here the <code>-t</code> option allows us to specify the name (or <em>tag</em>) of the image
                we are building. If we don’t use <code>-t</code>, a name will automatically be given to the
                docker image based on the location of the Dockerfile. It is recommended to
                always use the <code>-t</code> option so that we are able to choose a good name.<br>
                <u>note:</u> after <code>&ltimage_name&gt</code>, we can append a tag (<code>&ltimage_name&gt:&lttag&gt</code>) e.g.
                <code>my_image:lastest</code>

                <h3>Dockerfile commands</h3>
                <p>
                This are the commands that can be used in a <em>Dockerfile</em> to specify how the
                image should be built. They will create corresponding layers which will be
                cached so that, if some commands are changed or added, only the layers that
                need to be built again will be.
                </p>
                <ul>
                    <li><pre><code>FROM &ltos_name&gt</code></pre>
                        <u>note:</u> this allows us to pick the OS & distro we want for our image. It should
                        be the first instruction in our Dockerfile!
                    </li>
                    <li>
                        <pre><code>WORKDIR &ltdir_path&gt</code></pre>
                        <u>note:</u> this command is used to set the working directory for any <code>RUN, CMD,
                        ENTRYPOINT, COPY</code>, and <code>ADD</code> instructions that follow it in the Dockerfile. It
                        sets the working directory or the context for any commands that follow in the
                        Dockerfile. For example, if you use <code>RUN</code> commands after setting <code>WORKDIR</code>,
                        they will be executed in the context of the specified directory. <code>WORKDIR</code> also ensures
                        that the directory exists by creating it, if necessary, before proceeding with the
                        steps that follow. It's generally a good practice to use <code>WORKDIR</code> of
                        chaining <code>cd</code> commands in <code>RUN</code> instructions, as it makes the Dockerfile cleaner
                        and less error-prone
                    </li>
                    <li>
                        <pre><code>RUN &ltcommand&gt</pre></code>
                        <u>note:</u> this allows us to run any command. It is often used to install packages
                        (e.g. to install python)
                    </li>
                    <li>
                        <pre><code>COPY &lthost_file_path&gt &ltimage_destination_dir&gt</pre></code>
                        <u>note:</u> this is often used to copy code from the host to the docker image.
                        <code>&ltimage_destination_dir&gt</code> is the dir on the image where the files will be copied
                        and <code>&lthost_file_path&gt</code> is the path of the file that we want to copy on the host.
                    </li>
                    <li>
                        <pre><code>EXPOSE &ltport_number&gt</pre></code>
                        <u>note:</u> this allows us to pick the internal port that will be used by a docker
                        container ran based on this image.
                    </li>
                    <li>
                        <pre><code>CMD &ltcommand&gt &ltcommand_parameter&gt</pre></code>
                        <pre><code>CMD [“&ltcommand&gt”, “&ltcommand_parameter&gt”]</pre></code>
                        <u>note:</u> the two syntaxes are equivalent.<br>
                        <u>note:</u> this allows us to specifiy a "<em>complete</em>" command that will be run when the
                        container is ran. “<em>Complete</em>” means the command must contain both the
                        command istself but also all arguments passed to it. For example, we can
                        not only write <code>CMD sleep</code> and then try to pass the argument to the <code>sleep</code>
                        command (number of seconds to sleep) to the container when we run it. <b>We
                        must choose and hardocde the argument of the command in the Dockerfile and
                        can not change it when we run the container</b>. If we want to change the
                        argument of the command, we have to modify the Dockerfile and re-build the
                        image. If we want to be able to change the argument “dynamically” each time
                        we run the container, we must use the <code>ENTRYPOINT</code> command.<br>
                        <u>note:</u> we can overwrite the <code>CMD</code> command when launching the container by
                        specifying a command after the <code>&ltimage_name&gt</code> in the <code>docker run</code> command.
                        This is actually why we can not specify the parameter when we run the
                        container: the command in <code>CMD</code> is overwrittent by any command we pass
                        when we run the container! So if we have <code>CMD sleep</code> and we run <code>docker run
                        &ltimage_name&gt 5</code>, then the command that will be ran is actually just “<code>5</code>”
                        (because “<code>5</code>” overwrites <code>sleep</code>), and we will get an error.
                    </li>
                    <li>
                        <pre><code>ENTRYPOINT &ltcommand&gt</code></pre>
                        <pre><code>ENTRYPOINT ["&ltcommand&gt"]</code></pre>
                        <u>note:</u> the two syntaxes are equivalent.<br>
                        <u>note:</u> this allows us to specify the command that will be run when the docker
                        image is run.<br>
                        <u>note:</u> <b>with this command, we can specify the command in the Dockerfile without its arguments and pass
                        them "dynamically" when the container is launched</b>. This is the difference with <code>CMD</code>.
                        For example, we can write
                        <code>ENTRYPOINT sleep</code> and then run the container with the command <code>docker run
                        &ltimage_name&gt 10”</code>. In this example, <code>10</code> is the argument to the <code>sleep</code> bash
                        command which specifies how many seconds to sleep. This means that with
                        <code>ENTRYPOINT</code> we can change the arguments to the command that is ran when
                        the container is ran, each time we run a new container, without needing to
                        modify the image an re-build it. This is something we can not do with <code>CMD</code>
                        which requires the arguments to the command to be hard-coded in the
                        Dockerfile!<br>
                        <u>note:</u> the reason we can pass an argument to the <code>ENTRYPOINT</code> command is
                        because any command we pass when we run the container gets appended
                        to the command in <code>ENTRYPOINT</code>.<br>
                        <u>note:</u> usually, any command passed when we run the container gets appended
                        to the <code>ENTRYPOINT</code> command. However, if we use the <code>--entrypoint</code> option,
                        we can overwrite the <code>ENTRYPOINT</code> command (e.g. to change completly which
                        command gets run when we run the container). For example, <code>docker run --entrypoint
                        &ltcommand&gt &ltimage_name&gt</code> will run <code>&ltcommand&gt</code> instead of the command
                        specified in the <code>ENTRYPOINT</code> of the Dockerfile.<br>
                    </li>
                    <li>
                        <pre><code>ENTRYPOINT <command></code></pre>
                        <pre><code>CMD &ltcommand_parameter&gt</code></pre>
                        <u>note:</u> here we are considering the pattern where we run these two commands sequentially.<br>
                        <u>note:</u> taking advantage of the properties of <code>ENTRYPOINT</code> and <code>CMD</code>, this allows
                        us to accept an argument passed when we run the docker yet still set a default
                        argument. What will happen if we don’t give an argument (e.g. <code>docker run
                        &ltimage_name&gt</code>) is that, given that anything can be appended to <code>ENTRYPOINT</code>,
                        <code>&ltcommand_parameter&gt</code> (from the <code>CMD</code> instruction in the Dockerfile) will be appended to it. If we pass an
                        argument (e.g. <code>docker run &ltimage_name&gt &ltparameter&gt</code>), it will be appended
                        to <code>ENTRYPOINT</code> but will overwrite <code>CMD</code>, which means that it will be the
                        parameter used by docker. This way we are very flexible: <b>we can accept an
                        argument "dynamically" when we run the docker container but can also set a default
                        argument in case none is given when running the container</b>.
                    </li>
                </ul>

                <h3>See information about the build process of an image</h3>
                <pre><code>    docker history &ltimage_name&gt</code></pre>
                <u>note:</u> this shows information about each layer of the image, which correspond
                to the commands in the Dockerfile file. For each layer, the corresponding
                command is shown, as well as its size, its hash and the time when it was created.

                <h3>Login to a (private or public) registry in order to be able to push images there</h3>
                <pre><code>    docker login &ltregistry_name&gt</code></pre>
                <u>note:</u> if <registry_name> is not specified, docker will assume it is docker hub.
                However, we can also specify a private registry (e.g. that of our company)<br>
                <u>note:</u> after running this command, the CLI will ask you for your username and
                password to log you in.

                <h3>Run a container and link it to a previously running one</h3>
                <pre><code>    docker run --link &ltother_container_name&gt:&ltinternal_alias&gt &ltimage_name&gt</code></pre>
                
                <u>note:</u> this option is <b>considered legacy and should not be used!</b> It is useful to
                understand it but we should use docker-compose for that now!<br>
                <u>note:</u> <code>&ltother_container_name&gt</code> is the name of the (already running) container
                we want to connect the container we are launching to. <br>
                <u>note:</u> <code>&ltinternal_alias&gt</code> is the alias (name) used within the new container (in its
                code) to refer to the already running one.

                <h3>Syntax of <code>docker-compose.yaml</code> files</h3>

                <pre><code>
                version: &ltversion_number&gt
                services:
                    &ltservice_name&gt:
                        image: &ltimage_name&gt                      # if we want to include a pre-built 
                                                                 # image

                        build : &ltpath_to_dir_with_dockerfile&gt    # if we want to build the image for 
                                                                 # this service when we run the 
                                                                 # docker-compose. In this case we 
                                                                 # don't include the “image” field
                        ports:
                            - &lthost_port>:&ltcontainer_port&gt
                        links:
                            - &ltother_service_name&gt
                        environment:
                            - &ltenv_variable_name&gt:&ltenv_variable_value&gt
                        depends on:
                            - &ltother_service_name&gt
                        networks:
                            - &ltnetwork_name&gt
                        networks:
                            &ltnetwork_name&gt:
                </code></pre>

                <u>note:</u> this is a <code>.yaml</code> file that must be named <code>docker-compose.yaml</code><br>
                <u>note:</u> this syntax is for <code>&ltversion_number&gt</code> equal to <code>3</code>.<br>
                <u>note:</u> for version 3, the <code>links</code> section is no longer needed! The containers can
                find each other using the network that is built automatically by <code>docker-compose</code><br>
                <u>note:</u> we can use either <code>image</code> or <code>build</code>, not both.<br>
                <u>note:</u> <code>ports</code> allows us to map host and container ports, like when we use the <code>-
                p</code> option with the <code>docker run</code> command.

                <h3>Launch all the services in a <code>docker-compose.yaml</code> file at once</h3>
                <pre><code>    docker-compose up</code></pre>

                <h3>Docker engine architecture</h3>
                The docker engine is a stack composed of 3 elements:
                <ol>
                    <li>the docker CLI</li>
                    <li>the docker REST API</li>
                    <li>the docker Deamon</li>
                </ol>
                The docker CLI communicates with the docker REST API which itself
                communicates with the docker daemon. The docker daemon manages all the
                docker objects, like the images and containers.
                It is possible to run a docker CLI on a different host thant the one where the
                docker REST API and docker deamon are running. In this case we can connect
                the Docker CLI to the docker REST API of the remote host running the docker
                deamon. For example, we can run a docker contiainer on the remote host via
                the following command:
                <pre><code>    docker -H=&ltremote_host_IP&gt:&ltremote_host_port&gt run &ltimage_name&gt</code></pre>
                <u>note:</u> here <remote_host_IP> and <remote_host_port> are the IP and port of
                the remote host running the REST API and the daemon

                <h3>Constraining the ressources used by a docker container</h3>
                <pre><code>    docker run --cpus=&ltfraction&gt &ltimage_name&gt</code></pre>
                <pre><code>    docker run --memory=&ltnumber_mb&gtm &ltimage_name&gt</code></pre>
                <u>note:</u> <fraction> should be a number between 0 and 1 and represents the
                percentage of cpu usage<br>
                <u>note:</u> <number_mb> represents the number of megabytes of memory allocated
                to this container.

                <h3>Docker sotrage</h3>
                When docker is installed it creates the following directory struture:
                <pre><code>
                |-- /var/lib/docker
                    |-- aufs
                    |-- containers
                    |-- image
                    |-- volumes
                </code></pre>
                <p>
                Files related to images are stored in <code>/var/lib/docker/image</code> and files related to
                containers are stored in <code>/var/lib/docker/containers</code>.
                Images are built in a layered architecture, where each layer
                corresponds to a command in the Dockerfile used to build the image.
                Each layer contains the difference with respect to the preceding layer.
                Each layer is cached so that if we need to rebuild an image containing
                this layer, it can simply be taken from the cache and not built again for
                nothing.
                </p>
                <p>
                Once the image is built into a container, the layers are stored in a Read
                Only way. It is not possible to modify these layers unless we modify the
                Dockerfile and rebuild the image.
                Once we run the container, based on this image, a new additional Read
                and Write layer is created. This layer can be modified. It is meant to
                contain all of the data generated by the docker container which
                includes logs, temporary files or files modified by the user in the
                docker container.
                </p>
                <p>
                When we create a new file in the running container, it is created in the
                Read and Write layer.
                If we modify a file that was included in the image (and thus that is in
                the Read Only layer), a copy of this file is made and placed in the Read
                and Write layer. This means we can modify this file without altering the
                original one in the Read Only layers of the built image. This is called
                the “Copy on Write” mechanism
                </p>
                When the container is destroyed, the Read and Write layer is also
                destroyed, which means that the changes do not persist!
                If we wish for the changes made in a specific directory of the container to
                persist even after we destroy the container, we need to mount it to a directory
                on the host. There are two ways of doing this: Bind Mounts and Volume Mounts.
                Volume Mounts consist in letting docker automatically create a directory (a
                volume) to mount in <code>/var/lib/docker/volumes</code>. This can be done with the
                following command:

                <pre><code>    docker run -v &ltvolume_name&gt:&ltcontainer_dir&gt &ltimage_name&gt</code></pre>

                Here <code>&ltvolume_name&gt</code> is just the name of the volume (i.e. directory), not the full
                path! When we run this command, docker will automatically create the
                directory <code>/var/lib/docker/volumes/&ltvolume_name&gt</code> and mount the
                &ltcontainer_dir&gt directory on our container to it.
                This is useful for containers that will run in prod because they are at a
                standardized place in our filesystem which is supervised by docker. It avoids
                having to deal with containers having access to random places in the file
                system.
                Bind Mounts consist in giving docker the full path to a directory on our file
                system. It can be done with the following command:

                <pre><code>    docker run -v &lthost_dir_path&gt:&ltcontainer_dir&gt &ltimage_name&gt</code></pre>

                Here <code>&lthost_dir_path&gt</code> is the full path to the directory on the host we want to
                mount.
                Note that the <code>-v</code> syntax is the old way, now we should use <code>--mount</code>. It is
                better because it is more verbose and makes it clearer what we are doing. Here
                is the syntax:

                <pre><code>    docker run --mount type=&ltmount_type&gt,source=&ltsource&gt,target=&lttarget_path&gt &ltimage_name&gt</code></pre>

                Here <code>&ltmount_type&gt</code> is either <code>bind</code> or <code>volume</code>. 
                <code>&ltsource&gt</code> is the volume name, in the case of a volume mount, or the
                full path, in the case of a bind mount.
                <code>&lttarget_path&gt</code> is the path of the directory in the container that we
                want to mount.

                <h3>Docker networking</h3>
                When docker is installed, it creates 3 networks automatically:
                <ul>
                    <li>
                        <u>Bridge:</u> It is a private internal network created by docker ont he host.
                        Containers attach to this network by default and get an internal IP
                        address. Containers on the Bridge network can access each other
                        using this internal IP address. To access the containers outside the
                        host, we need to map the containers ports to host ports.
                    </li>
                    <li>
                        <u>host:</u> this network removes all network compartimentalization,
                        meaning that a container wil automatically be accessible from outside
                        on its port without needing to map it to a host port. E.g. if a container
                        is ran on “internal” port 5000, and if it is on the host network, then it
                        will be accessible externally to anyone on the host’s IP at this same
                        port. This means that on this network, we can only run on container
                        per port, given that the container ports corespond to real host ports.
                    </li>
                    <li>
                        <u>none:</u> When ran on this network, the containers are not attached to
                        any network and don’t have any access to the external network or to
                        other containers. They are isolated.
                    </li>
                </ul>
                Bridge is the default network a container gets attached to. To attach the
                container to any other network, we need to specify the network when launching
                the container with the command:

                <pre><code>    docker run &ltimage_name&gt --network=&ltnetwork_name&gt</code></pre>

                <u>note:</u> here <code>&ltnetwork_name&gt</code> can be either <code>Bridge, host,</code> or <code>none</code>.
                By default, the only internal network created by docker is Bridge, if we wish to
                create another internal network (e.g. to isolate together a group of containers),
                we can do so with the command:
                <pre><code>    docker network create --driver &ltdriver&gt \
                          --subnet &ltIP_address&gt/&ltprefix_length&gt \
                          --gateway &ltgateway_IP_address&gt &ltnetwork_name&gt</code></pre>

                <u>note:</u> <code>&ltdriver&gt</code> is the driver used to manage the network, by default it is set to
                bridge<br>
                <u>note:</u> <code>&ltIP_address&gt/&ltprefix_length&gt</code> specifies a range of IP addresses in CIDR
                notation. For example <code>192.168.1.0/24</code>. So <code>&ltIP_address&gt</code> is the prefix.<br>
                <u>note:</u> <code>&ltgateway_IP_address&gt</code> allows us to specify the address of the gateway of our network<br>
                All networks that exist can be listed with the following command:

                <pre><code>    docker network ls</code></pre>

                To get more information about a particular network, we can inspect it using the
                following command:

                <pre><code>    docker network inspect &ltnetwork_name&gt</code></pre>

                To delete a network, we can use

                <pre><code>    docker network rm &ltnetwork_name&gt</code></pre>
                <pre><code>    docker network rm &ltnetwork_id&gt</code></pre>
                <u>note:</u> both commands are equivalent.<br>
                <u>note:</u> Remember that the <code>docker inspect</code> command can be used to inspect
                more in detail the network settings of a container (see the entry for this command above).<br>
                <u>note:</u> Containers can reach each other just using their container names,
                without need of using their internal IP address. This is done via
                an internal DNS server that docker runs. Note that it is better to
                reach other containters using their names because it is more robust
                than using their IP addresses, as IP addresses can change when the
                container is rebooted.


            </div>
        </div>

        <div id="left-panel">
        </div>
        <script src="script.js"></script>
    </body>
</html>